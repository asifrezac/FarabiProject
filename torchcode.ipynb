{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#importing libraries\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","#device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-100-python.tar.gz to ./data\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["def get_train_valid_loader(data_dir, batch_size, augment, random_seed, valid_size=0.1, shuffle=True):\n","    normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n","\n","    # define transforms\n","    valid_transform = transforms.Compose([\n","        transforms.Resize((227, 227)), \n","        transforms.ToTensor(), \n","        normalize\n","    ])\n","    if augment:\n","        train_transform = transforms.Compose([\n","            transforms.RandomCrop(32, padding=4),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","    else:\n","        train_transform = transforms.Compose([\n","            transforms.Resize((227, 227)),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","\n","    # load the dataset\n","    train_dataset = datasets.CIFAR100(root=data_dir, train=True, download=True, transform=train_transform)\n","\n","    valid_dataset = datasets.CIFAR100(root=data_dir, train=True, download=True, transform=valid_transform)\n","\n","    num_train = len(train_dataset)\n","    indices = list(range(num_train))\n","    split = int(np.floor(valid_size * num_train))\n","\n","    if shuffle:\n","        np.random.seed(random_seed)\n","        np.random.shuffle(indices)\n","\n","    train_idx, valid_idx = indices[split:], indices[:split]\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n","\n","    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n","\n","    return (train_loader, valid_loader)\n","\n","\n","def get_test_loader(data_dir, batch_size, shuffle=True):\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","    # define transform\n","    transform = transforms.Compose([transforms.Resize((227, 227)), transforms.ToTensor(),normalize])\n","\n","    dataset = datasets.CIFAR100(root=data_dir, train=False,download=True, transform=transform)\n","\n","    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","\n","    return data_loader\n","\n","\n","# CIFAR100 dataset\n","train_loader, valid_loader = get_train_valid_loader(data_dir='./data', batch_size=64, augment=False, random_seed=1)\n","\n","test_loader = get_test_loader(data_dir='./data', batch_size=64)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#defining the alexnet model\n","\n","class AlexNet(nn.Module):\n","    def __init__(self, num_classes=100):\n","        super(AlexNet, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n","            nn.BatchNorm2d(96),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2))\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2))\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(384),\n","            nn.ReLU())\n","        self.layer4 = nn.Sequential(\n","            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(384),\n","            nn.ReLU())\n","        self.layer5 = nn.Sequential(\n","            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2))\n","        self.fc = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(9216, 4096),\n","            nn.ReLU())\n","        self.fc1 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU())\n","        self.fc2 = nn.Sequential(\n","            nn.Linear(4096, num_classes))\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = self.layer5(out)\n","        out = out.reshape(out.size(0), -1)\n","        out = self.fc(out)\n","        out = self.fc1(out)\n","        out = self.fc2(out)\n","        return out"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["#setting the hyperparameters\n","num_classes = 100\n","num_epochs = 20\n","batch_size = 64\n","learning_rate = 1e-4\n","\n","model = AlexNet(num_classes).to(device)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Loss and SGD optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(\n","    model.parameters(), lr=learning_rate, weight_decay=0.005, momentum=0.9)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Loss and Adam optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.005, amsgrad=False, foreach=None, maximize=False, capturable=False)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Train the model\n","total_step = len(train_loader)\n","\n","#training and validation\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        # Move tensors to the configured device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","          .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","    # Validation\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in valid_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            del images, labels, outputs\n","\n","        print('Accuracy of the network on the {} validation images: {} %'.format(\n","            5000, 100 * correct / total))\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"340e956ee656efd8fdfb480dc033c937d9b626f8b21073bd1b5aa2a469586ea6"}}},"nbformat":4,"nbformat_minor":2}
